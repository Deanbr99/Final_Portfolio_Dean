[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Mini-Project 5",
    "section": "",
    "text": "Dean Brooker Mini-Project 5\n\nTowards the end of Section 1, the authors say “As ‘statistical significance’ is used less, statistical thinking will be used more.” Elaborate on what you think the authors mean. Give some examples of what you think embodies “statistical thinking.”\n\nWhat I think the author means is the idea that as people move away from saying whether a finding is relevant will no longer be simply judged by it simply passing a p value test, but the research will be judged by whether the researcher can argue their methods and findings in a way that proves a point. An example of statistical thinking in my eyes is if the researcher gets a p value of 0.1, they will be able to argue why it is 0.1 and not below 0.05, and why this research is still relevant even if the p value is 0.1.An example could be, a new improvement to squash balls increased rallies by 15 seconds per rally on average but the p value is 0.07, then the statistical thinking should look more into this, maybe get more data, rerun the study. Just because it failed, doesn’t mean there isn’t something there.\n\nSection 2, third paragraph: The authors state “A label of statistical significance adds nothing to what is already conveyed by the value of p; in fact, this dichotomization of p-values makes matters worse.” Elaborate on what you think the authors means.\n\nWhat I think the author is trying to get at is that a p value being said to be significant and proving something does not mean that it is true. A very low p value just means the result is very rare if there were no real effects so researchers should use thinking to convince the reader that the research shows something important rather than hiding behind a p value just to prove what they studying has an effect. The author is saying that when people say 0.049 is significant and 0.051 is not significant, the problem is just being made worse because researchers have something to hide behind when judged. Someone could say, “I don’t think your research on whether carrots help you see in the dark proves anything, a researchers can simply say, “Its significant” and the current scientist community will back up the researcher and not be curious like the person challenging the researcher.\n\nSection 2, end of first column: The authors state “For the integrity of scientific publishing and research dissemination, therefore, whether a p-value passes any arbitrary threshold should not be considered at all when deciding which results to present or highlight.” Do you agree or disagree? How should it be decided which results to present/highlight in scientific publishing?\n\nI do not think p values should be, the be all and end all. Last semester for my econometrics project, we investigated whether EV cars has reduced carbon emissions in the US. The obvious and truthful answer is absolutely no. There are so few EV cars in the US, it is just really not having an effect yet on reducing carbon emissions in the US by state. But in our research we changed the variable of research to EV/per-capita in each state and with that, that variable was significant at a 0.05 level. Therefore, we could write a paper that portrayed on a per capita basis, EV cars are already influencing reducing carbon emissions. What I am trying to say is, if I, a very terrible academic could “create” significance, a great academic with more time could easily create significance out of nothing. The p value should not be the reason academic research should be highlighted\nThe way I think research should be presented, is if the researcher themselves pave the way for future of research in the field and not by proving something. For example, I think a researcher who says, “I have proved cursive writing improves attention to detail in children” should not be highlighted but the researcher that says, “Cursive writing improves attention to detail in kids, through my extensive research, more research and areas of interest in this topic is whether this increased attention to detail decreases creativity in children. I think research should highlighted and published if its sole purpose is to pave the future and not give “significance” and recognition to a researcher.\n4)Section 3, end of page 2: The authors state “The statistical community has not yet converged on a simple paradigm for the use of statistical inference in scientific research – and in fact it may never do so. A one-size-fits-all approach to statistical inference is an inappropriate expectation.” Do you agree or disagree? Explain.\nYes I agree with this. I agree that we should move away from the one size fits all. Different research should use different methods to decide on significance. With data from hospitals as discussed, often with large amounts of data it is easy to get a small p value but maybe with another method that is discussed, like false positive risk or analysis or credibility, a fuller picture can be portrayed. I do not know anything about those methods and that is sad in my eyes. Reading about all these other methods only in my senior year of college is sad and says something about academia. Academia is so pushed in the one size fits all, us college students aren’t getting the opportunity to be exposed to anything but the p value. If we start teaching undergraduates about other methods, maybe the next generation can be more thoughtful in statistical inference.\n5) Section 3.2: The authors note that they are envisioning “a sort of ‘statistical thoughtfulness’.” What do you think “statistical thoughtfulness” means? What are some ways to demonstrate “statistical thoughtfulness” in an analysis?\nI really liked the idea that, thoughtful research means being cautious with language and avoiding overconfident terms like “significant”. Often a paper says, for certain this is what is happening and then 3 years later another paper shows the previous paper was wrong. The first paper could have signs that they know they were wrong but they used overconfident language and try make their research sound more significant just to get published or highlighted. This paper argues that statistical thoughtfulness is presenting info not just so they can get published. An example would be clearly explaining what the confidence interval tells you and what it doesn’t tell us. It is presenting a picture and also explaining what picture it is not telling.\n6) Section 3.2.4: A few of the authors of papers in this special issue argue that some of the terminology used in statistics, such as “significance” and “confidence” can be misleading, and they propose the use of “compatibility” instead. What you do you think they believe the problem is? Do you agree or disagree (that there is a problem and that changing the name will help)?\nThey think the problem currently is “confidence” and significance is too strong of language. Significant means important and confidence sounds too certain.\nI do not agree with this really. I think just changing the wording is not at the root problem. Yes, I understand, all these suggestions paired with each other, moves the statistics community forward but I think changing language is low on the list. I think, this suggestion is too old school of thought, like that it is language that is the problem, but I think it is the method, data and inference, which is more of the problem\n7) Find a quote or point that really strikes you (i.e., made you think). What is the quote (and tell me where to find it), and why does it stand out to you?\n“Edgeworth’s (1885) original intention for statistical significance was simply as a tool to indicate when a result warrants further scrutiny.”\nFrom a bit of reading online, it appears that Edgeworth introduced many early ideas about the use of probability and inference in statistics. He argues that statistical significance should be a signal for further scrutiny and investigation and not a final decision. I was very interested in Edgeworth so I looked him up a bit. It was difficult to find stuff. Playing around with ChatGPT, it said that, Edgeworth believed that different problems may require different statistical tools and probability should be viewed as a tool for reasoned judgement. I could not find the sources, AI was referring to but if this info is true, it is incredible to see that someone so long ago, was saying exactly what this author was saying."
  },
  {
    "objectID": "posts/04-Bayez/index.html",
    "href": "posts/04-Bayez/index.html",
    "title": "Mini-Project",
    "section": "",
    "text": "##This project will attempt to answer the question of what is the probability\n##Nadla wins a point on his own serve against Novak Djokovic,at the French Open ?\n\n##To answer this question, we will use bayesian analysis where we will make some\n##informed assumptions paired with availiable data to create a probability that, \n##Nadal will wins a point on his own serve against Djokovic, at the French Open\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nps &lt;- seq(0.1, 200, length.out = 5000)\n\n\n##non-informed prior\n##beta(1,1)\nnoninformative_alpha &lt;- 1\nnoninformative_beta &lt;- 1\n\nnoninformative_prior &lt;- dbeta(ps,\n                              noninformative_alpha, noninformative_beta)\n\n##Informative Prior with Match Stats\nmatch_mean &lt;- 46 / 66\nmatch_se &lt;- 0.05657\nmatch_var &lt;- match_se^2\n\ntarget_mean &lt;- match_mean\ntarget_var &lt;- match_var\n\ninformative_alphas &lt;- seq(0.1, 200, length.out = 5000)\ninformative_betas &lt;- (informative_alphas * (1 - target_mean)) / target_mean\ninformative_vars &lt;- (informative_alphas * informative_betas) / ((informative_alphas + informative_betas)^2 * (informative_alphas + informative_betas + 1))\n\nparam_df &lt;- tibble(informative_alphas, informative_betas, informative_vars) |&gt;\n  mutate(dist_to_target = abs(informative_vars - target_var))\n\nbest_params &lt;- param_df |&gt; filter(dist_to_target == min(dist_to_target))\n\ninformative_alpha_match &lt;- best_params$informative_alphas\ninformative_beta_match &lt;- best_params$informative_betas\n\ninformative_alpha_match\n\n[1] 45.28644\n\ninformative_beta_match\n\n[1] 19.68976\n\n##Informative Prior from Announcer\nalphas &lt;- seq(0.01, 1000, length.out = 2000) \nbetas &lt;- alphas / 3\n\n\n\ntarget_prob &lt;- 0.04\nprob_less_0.7 &lt;- pbeta(0.70, alphas, betas)\n\ntibble(alphas, betas, prob_less_0.7) |&gt;\n  mutate(close_to_target = abs(prob_less_0.7 - target_prob)) |&gt;\n  filter(close_to_target == min(close_to_target))\n\n# A tibble: 1 × 4\n  alphas betas prob_less_0.7 close_to_target\n   &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;           &lt;dbl&gt;\n1   182.  60.5        0.0400       0.0000205\n##When we created our informative priors, we assumed independence of points, ie\n##If Nadal wins two points in a row with his serve, the next serve was indepedent ##if the previous two or that all his opponents are of equal skill level\n## We are assuming game lengths are the same, like some tennis matches, \n## Nadal will serve a lot more\nlibrary(tidyverse)\n\nps &lt;- seq(0, 1, length.out = 1000)\n\nnoninformative_alpha &lt;- 1\nnoninformative_beta &lt;- 1\n\ninformative_alpha_match &lt;- 45.28644\ninformative_beta_match &lt;- 19.68976\n\ninformative_alpha_announce &lt;- 181.599\ninformative_beta_announce &lt;- 60.53299\n\nnoninformative_prior &lt;- dbeta(ps, noninformative_alpha, noninformative_beta)\ninformative_prior &lt;- dbeta(ps, informative_alpha_match, informative_beta_match)\ninformative_prior_announce &lt;- dbeta(ps, informative_alpha_announce, informative_beta_announce)\n\nprior_plot &lt;- tibble(ps, noninformative_prior, informative_prior, informative_prior_announce) |&gt;\n  pivot_longer(2:4, names_to = \"prior_type\", values_to = \"density\") |&gt;\n  mutate(prior_type = recode(prior_type,\n                             \"noninformative_prior\" = \"Non-informative Prior\",\n                             \"informative_prior\" = \"Informative Prior (Match Data)\",\n                             \"informative_prior_announce\" = \"Informative Prior (Announcer)\"))\n\nggplot(data = prior_plot, aes(x = ps, y = density, colour = prior_type)) +\n  geom_line() +\n  scale_colour_viridis_d(end = 0.9) +\n  theme_minimal() +\n  labs(x = \"p (Probability Nadal wins point on serve)\",\n       y = \"Density\",\n       colour = \"Prior Type\",\n       title = \"Three Prior Distributions for Nadal's Serve Performance\")\nps &lt;- seq(0, 1, length.out = 1000)\n\nnoninformative_alpha &lt;- 1+56\nnoninformative_beta &lt;- 84 -56+1\n\ninformative_alpha_match &lt;- 45.28644 +56\ninformative_beta_match &lt;- 84-56+19.68976\n\ninformative_alpha_announce &lt;- 181.599+56\ninformative_beta_announce &lt;- 84-56+60.53299\n\nnoninformative_post &lt;- dbeta(ps, noninformative_alpha, noninformative_beta)\ninformative_post &lt;- dbeta(ps, informative_alpha_match, informative_beta_match)\ninformative_post_announce &lt;- dbeta(ps, informative_alpha_announce, informative_beta_announce)\n\npost_plot &lt;- tibble(ps, noninformative_post, informative_post, informative_post_announce) |&gt;\n  pivot_longer(2:4, names_to = \"prior_type\", values_to = \"density\") |&gt;\n  mutate(prior_type = recode(prior_type,\n                             \"noninformative_prior\" = \"Non-informative Prior\",\n                             \"informative_prior\" = \"Informative Prior (Match Day)\",\n                             \"informative_prior_announce\" = \"Informative Prior (Announcer)\"))\n\nggplot(data = post_plot, aes(x = ps, y = density, colour = prior_type)) +\n  geom_line(size=1.2) +\n  scale_colour_viridis_d(end = 0.9) +\n  theme_minimal() +\n  labs(x = \"p (Probability Nadal wins point on serve)\",\n       y = \"Density\",\n       colour = \"Prior Type\",\n       title = \"Three Posterior Distributions for Nadal's Serve Performance\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\nnoninformative_alpha &lt;- 1+56\nnoninformative_beta &lt;- 84 -56+1 \n\ninformative_alpha_match &lt;- 45.28644 +56\ninformative_beta_match &lt;- 84-56+19.68976\n\ninformative_alpha_announce &lt;- 181.599+56\ninformative_beta_announce &lt;- 84-56+60.53299\n\n\nmean_noninformative &lt;- 57/ (57+29)\nmean_informative &lt;- 101.28644/ (101.28644+ 47.68976)\nmean_informative_announce &lt;- 237.599/(88.53299+237.599)\n\nmean_noninformative\n\n[1] 0.6627907\n\nmean_informative\n\n[1] 0.6798834\n\nmean_informative_announce\n\n[1] 0.7285363\n\n##NonInformative\nqbeta(0.05,57,29)\n\n[1] 0.5772453\n\nqbeta(0.95,57,29)\n\n[1] 0.7440061\n\n##Informative\nqbeta(0.05,101.28644,47.68976)\n\n[1] 0.6158464\n\nqbeta(0.95,101.28644,47.68976)\n\n[1] 0.7411652\n\n##Informative_Announce\nqbeta(0.05,237.599,88.53299)\n\n[1] 0.6873017\n\nqbeta(0.95,237.599,88.53299)\n\n[1] 0.7681751\n## (1)The credible interval for noninformative (0.577;0.744)\n## (2)The credible interval for informative_novak_stats (0.6158;0.7412)\n## (3)The credible intervals for informative_announce (0.687,0.768)\n\n## The posteriors differ because the priors have different assumptions:\n## The noninformative is driven simply by the data\n## The match data informative one is based on match data and the data\n## The announcer posterior has a very strong prior so may be overpowering \n## the data somewhat\n\n##The variance of the noninformative is the highest as shown by the graph\n\n##I would choose the informative posterior(2) using the match stats for the prior\n##The reason I have chosen this one is I believe the announcers one is too narrow\n## Nadal is the greatest tennis player on clay, so therefore he will have an\n## extremely high serve win ratio but the intial question was, what will his win \n## serve ratio be against Novak, who is an incredible tennis player too.\n## The announcer posterior is over confident in Nadal's serve when playing Novak,\n## as we assumed independence and that every opponent is equal but not every \n## opponent is equal. I feel that the announcer one is overdriven by the prior.\n\n## We do not lose much on an credible interval when selecting (2) over (3) and \n## looking at the density graphs, I feel that the little moved less graph is \n## more reflective of when Nadal plays Novak\n\n## What I found from this project is that a posterior can be overdriven by\n## a prior if the prior is too strong, What this does is make the density too \n## high and overstated by the prior. I learned that the smallest credible \n## interval isnt always the best. You have to consider a lot of factors to choose\n## the best predictor"
  },
  {
    "objectID": "posts/02-Story/index.html",
    "href": "posts/02-Story/index.html",
    "title": "Mini Project 2",
    "section": "",
    "text": "Dean Brooker\nMini Project\nA True Statistical American Hero\nThat is when it all changed. I changed it all.\nAfter graduation, in 1974, I decided to take some time off and travel around Vietnam. I arrived in Saigon, with my backpack, three shirts, and two pairs of pants. I had no plan.\nI heard a bomb explode, from far into the horizon. Then I heard another explosion. Then another. As the night went on, the bombs sounded as if they were getting closer to me. I remembered in school that sound travels at something like 300 meters a second so now wide awake, I decided to see how far the bombs were away from me. Way into the horizon, I would see a flash of light, and then I would count the amount of time it took for me to hear the blast. One…two…three… Fourteen seconds. Fourteen seconds multiplied by 300 meters means the blast was 4.2 kilometers away more or less. That was my estimate of how far the bombs were, away from me. After that, I could fall asleep, knowing the bombs were far away.\nThe next morning, I decided I would go for a hike in the jungle. The jungle was thick and the air was humid. After an hour of walking, I bumped into a man wearing camouflage clothing. He ran towards me and shouted, “You are in a war zone, get away”. I shouted back, “No, I am on holiday, nothing will stop my holiday.”\nThe man approached me and said, “I lost my platoon 20 minutes ago, I will never find them again !” I replied in a rather humorous tone, “Well we can find your platoon in no time.”\nI asked how fast the platoon walked. He said that they walk at a steady pace of 5 kilometers per hour. I explained that the marching speed was our parameter. The lost soldier said they were walking exactly due east. I simply explained that if they were twenty minutes ahead, a quarter of an hour, and moving at 5 km/h, they were 1.67km due east from us. We just need to walk a bit faster than 5km/h and we will catch them in no time.\nThe lone soldier said, “Did you just use an estimator to infer the location of my platoon based on the parameter of their marching speed?”\nI smirked and replied, “Yes, yes I did !”\nI joined the lone soldier and in no time, we found his platoon. When we arrived we found the platoon, in a gunfight with the\nOne soldier shouted, “I have no clue how many North Vietnamese soldiers there are?”\nI replied, “Well it would be easy to find out more or less how many there are !”\nThere were ten big trees, North Vietnamese soldiers were hiding behind. I snuck over our platoon’s cover and counted how many soldiers were behind two trees. I counted 30 behind two trees. Using my sample, we were up against 150 North Vietnamese soldiers.\nOne soldier shouted, “We have lost 2 soldiers in the last 30 minutes, and they have lost 30 soldiers in the last 30 minutes!”\nI shouted, “We must keep fighting! If we define X as the number of enemies we eliminate in a given time, it’s a random variable following a predictable trend! So far, our killing rate is 30 North Vietnamese every 30 minutes, therefore following this we will kill the remaining 120 soldiers in two hours!\nTwo hours and 20 minutes later, we had killed the entire opposing force.\nA frustrated soldier shouted, “You said it would take two hours!”:\nI explained, “Maybe the sample of the two trees was biased! “Maybe the two trees I checked had fewer soldiers than the others, meaning the original estimate of 150 soldiers could have been too low, maybe there were 180 soldiers. I didn’t account for variance either. Variance on the other hand refers to how much the number of enemies we eliminate fluctuates. Our kill rate of 30 per 30 minutes was based on a short sample, but in reality, some fighting waves are more intense than others. The randomness of battle means the actual elimination rate isn’t constant and we should have accounted for variance !”\nThe platoon of flabbergasted soldiers nodded and agreed.\nOne soldier asked, “Who are you? Why are you here?”\nI simply replied, “I am on holiday here in Vietnam, I am just a boy from South Africa!”\nA soldier shouted, “We may have won the battle, but we still need to get back to base!”\nI shouted, “I can help!\nThere were three routes: one along the riverbank, one through the thick of the jungle, and one over the mountain. Based on my reading of war novels, I knew there would be more enemy troops along the river route, as it was the easiest and closest to water. Based on my reading, I decided the jungle route gave us the most cover!\nI shouted, “Given the observed data, enemy patrol patterns, terrain difficulty, and past escape routes, the likelihood function suggests the jungle path has the highest probability of getting us back safely,”\nAfter three hours of walking, we arrived safely at the base. The one soldier said that I needed to meet General Johnson, as he would thank us for getting his troops back safely.\nI entered the war room and saw General Johnson playing a war game with die. I watched and worked out General Johnson was making mistakes!\n“You are basing your strategy on just a few dice rolls, that is not a reliable approach, what you need is a proper random sample !” A single roll is not enough but if you roll enough times, you get a better estimate of the true probabilities !”, I explained.\nOne general folded his arms and said, So you saying we need more data?”\nI nodded. “Exactly. A good estimator is consistent, meaning that as you increase the sample size, your results get closer to the true probabilities. If you roll enough times, your estimates of battlefield success rates will stabilize and reflect reality more accurately!”\nI sat in the room and continued to watch the generals play the war game.\nA soldier ran into the room and said, there are ten ships in the bay coming to attack, we need to shoot them down.\nThe general shouted, “Our missiles have an 80% success rate, so let’s just take 12 missiles to be the same, then surely we will sink all ten ships !”\nI replied, “Sadly that is wrong !”\nThe president of the US had just walked in and asked, “Who exactly said that and who are you !”\nI answered, “My name is Dean, I am on holiday!”\nI explained that we had a binomial problem on our hands. If the probability of success was 80% per missile, using a binomial distribution, with ten successes needed, we would need 16 missiles to ensure 99.99% success in shouting down the ten boats !”\nThe general shouted, “You heard the holidaymaker, grab 16 missiles”\nAfter this long day, I was becoming quite peckish. I thanked the general and president for having me and walked down the street in search of the nearest restaurant.\nTwo days later, I returned to the USA. When I landed at the US airport, I saw a headline in one of the newspapers that said, “True American Hero: Boy on holiday, saves lost soldier, wins a battle in the Vietnamese jungle, fixes US war game, and shoots down 10 North Vietnamese ships !”\nI thought to myself, what an incredible story. I grabbed the newspaper and read the story. It was incredible. I hope one day, I get to meet this boy!"
  },
  {
    "objectID": "posts/01-Sim/index.html",
    "href": "posts/01-Sim/index.html",
    "title": "Dean Brooker Mini-Project1",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nn &lt;- 5            # sample size\nmu &lt;- 10          # population mean\nsigma &lt;- 2        # population standard deviation\n\ngenerate_samp_min &lt;- function(mu, sigma, n) {\n  \n  single_sample &lt;- rnorm(n, mu, sigma)\n  sample_min &lt;- min(single_sample)\n  \n  return(sample_min)\n}\n\n## test function once:\ngenerate_samp_min(mu = mu, sigma = sigma, n = n)\n\n[1] 8.570612\n\nnsim &lt;- 5000      # number of simulations\n\n## code to map through the function. \n## the \\(i) syntax says to just repeat the generate_samp_mean function\n## nsim times\nmins &lt;- map_dbl(1:nsim, \\(i) generate_samp_min(mu = mu, sigma = sigma, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmins_df &lt;- tibble(mins)\nmins_df\n\n# A tibble: 5,000 × 1\n    mins\n   &lt;dbl&gt;\n 1  9.37\n 2  7.19\n 3 11.3 \n 4  9.11\n 5  6.45\n 6  9.77\n 7  6.89\n 8  7.30\n 9  8.69\n10  5.90\n# ℹ 4,990 more rows\n\nggplot(data = mins_df, aes(x = mins)) +\n  geom_histogram(colour = \"deeppink4\", fill = \"deeppink1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Mins\",\n       title = paste(\"Sampling Distribution of the \\nSample Mean when n =\", n))\n\n\n\n\n\n\n\nmins_df |&gt;\n  summarise(mean_samp_dist = mean(mins),\n            var_samp_dist = var(mins),\n            sd_samp_dist = sd(mins))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1           7.66          1.74         1.32\n\n#\nn &lt;- 5            # sample size\nmu &lt;- 10          # population mean\nsigma &lt;- 2        # population standard deviation\n\ngenerate_samp_max &lt;- function(mu, sigma, n) {\n  \n  single_sample &lt;- rnorm(n, mu, sigma)\n  sample_max &lt;- max(single_sample)\n  \n  return(sample_max)\n}\n\n## test function once:\ngenerate_samp_max(mu = mu, sigma = sigma, n = n)\n\n[1] 11.78113\n\nnsim &lt;- 5000      # number of simulations\n\n## code to map through the function. \n## the \\(i) syntax says to just repeat the generate_samp_mean function\n## nsim times\nmaxs &lt;- map_dbl(1:nsim, \\(i) generate_samp_max(mu = mu, sigma = sigma, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmaxs_df &lt;- tibble(maxs)\nmaxs_df\n\n# A tibble: 5,000 × 1\n    maxs\n   &lt;dbl&gt;\n 1  13.1\n 2  11.6\n 3  11.8\n 4  13.3\n 5  11.5\n 6  11.2\n 7  13.1\n 8  12.2\n 9  14.6\n10  13.6\n# ℹ 4,990 more rows\n\nggplot(data = maxs_df, aes(x = maxs)) +\n  geom_histogram(colour = \"deeppink4\", fill = \"deeppink1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Means\",\n       title = paste(\"Sampling Distribution of the \\nSample Mean when n =\", n))\n\n\n\n\n\n\n\nmaxs_df |&gt;\n  summarise(mean_samp_dist = mean(maxs),\n            var_samp_dist = var(maxs),\n            sd_samp_dist = sd(maxs))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1           12.3          1.84         1.36\n##uniform\nn &lt;- 5            # sample size\nmu &lt;- 10          # population mean\nsigma &lt;- 1.732    # population standard deviation (calculated by hand)\no1=7\no2=13\n\ngenerate_samp_min &lt;- function(n, mu, sigma) {\n  \n  single_sample &lt;- runif(n, o1,o2)\n  sample_min &lt;- min(single_sample)\n  \n  return(sample_min)\n}\n\n## test function once:\ngenerate_samp_min(mu = mu, sigma = sigma, n = n)\n\n[1] 9.249944\n\nnsim &lt;- 5000      # number of simulations\n\n## code to map through the function. \n## the \\(i) syntax says to just repeat the generate_samp_mean function\n## nsim times\nmins &lt;- map_dbl(1:nsim, \\(i) generate_samp_min(mu = mu, sigma = sigma, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmins_df &lt;- tibble(mins)\nmins_df\n\n# A tibble: 5,000 × 1\n    mins\n   &lt;dbl&gt;\n 1  7.17\n 2 10.3 \n 3  8.08\n 4  7.37\n 5  7.40\n 6  7.15\n 7  7.19\n 8  9.09\n 9  7.22\n10  7.28\n# ℹ 4,990 more rows\n\nggplot(data = mins_df, aes(x = mins)) +\n  geom_histogram(colour = \"deeppink4\", fill = \"deeppink1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Mins\",\n       title = paste(\"Sampling Distribution of the \\nSample Mean when n =\", n))\n\n\n\n\n\n\n\nmins_df |&gt;\n  summarise(mean_samp_dist = mean(mins),\n            var_samp_dist = var(mins),\n            sd_samp_dist = sd(mins))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1           8.00         0.722        0.850\nn &lt;- 5            # sample size\nmu &lt;- 10          # population mean\nsigma &lt;- 1.732       # population standard deviation\no1=7\no2=13\n\ngenerate_samp_max &lt;- function(mu, sigma, n) {\n  \n  single_sample &lt;- runif(n, o1,o2)\n  sample_max &lt;- max(single_sample)\n  \n  return(sample_max)\n}\n\n## test function once:\ngenerate_samp_max(mu = mu, sigma = sigma, n = n)\n\n[1] 12.86532\n\nnsim &lt;- 5000      # number of simulations\n\n## code to map through the function. \n## the \\(i) syntax says to just repeat the generate_samp_mean function\n## nsim times\nmaxs &lt;- map_dbl(1:nsim, \\(i) generate_samp_max(mu = mu, sigma = sigma, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmaxs_df &lt;- tibble(maxs)\nmaxs_df\n\n# A tibble: 5,000 × 1\n    maxs\n   &lt;dbl&gt;\n 1 11.9 \n 2 12.8 \n 3 12.8 \n 4 12.5 \n 5 13.0 \n 6 12.7 \n 7 12.7 \n 8 10.0 \n 9  9.52\n10 12.4 \n# ℹ 4,990 more rows\n\nggplot(data = maxs_df, aes(x = maxs)) +\n  geom_histogram(colour = \"deeppink4\", fill = \"deeppink1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Means\",\n       title = paste(\"Sampling Distribution of the \\nSample Mean when n =\", n))\n\n\n\n\n\n\n\nmaxs_df |&gt;\n  summarise(mean_samp_dist = mean(maxs),\n            var_samp_dist = var(maxs),\n            sd_samp_dist = sd(maxs))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1           12.0         0.694        0.833\n##exponential\nn &lt;- 5            # sample size\nmu &lt;- 2         # population mean\nsigma &lt;- 2    # population standard deviation (calculated by hand)\nlambda=0.5\n\ngenerate_samp_min &lt;- function(mu, sigma, n) {\n  \n  single_sample &lt;- rexp(n, lambda)\n  sample_min &lt;- min(single_sample)\n  \n  return(sample_min)\n}\n\n## test function once:\ngenerate_samp_min(mu = mu, sigma = sigma, n = n)\n\n[1] 1.016156\n\nnsim &lt;- 5000      # number of simulations\n\n## code to map through the function. \n## the \\(i) syntax says to just repeat the generate_samp_mean function\n## nsim times\nmins &lt;- map_dbl(1:nsim, \\(i) generate_samp_min(mu = mu, sigma = sigma, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmins_df &lt;- tibble(mins)\nmins_df\n\n# A tibble: 5,000 × 1\n     mins\n    &lt;dbl&gt;\n 1 0.279 \n 2 0.461 \n 3 1.12  \n 4 0.0691\n 5 0.132 \n 6 0.264 \n 7 0.0515\n 8 1.05  \n 9 0.0178\n10 1.20  \n# ℹ 4,990 more rows\n\nggplot(data = mins_df, aes(x = mins)) +\n  geom_histogram(colour = \"deeppink4\", fill = \"deeppink1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Mins\",\n       title = paste(\"Sampling Distribution of the \\nSample Mean when n =\", n))\n\n\n\n\n\n\n\nmins_df |&gt;\n  summarise(mean_samp_dist = mean(mins),\n            var_samp_dist = var(mins),\n            sd_samp_dist = sd(mins))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1          0.405         0.153        0.392\nn &lt;- 5            # sample size\nmu &lt;- 2         # population mean\nsigma &lt;- 2  # population standard deviation\nlambda=0.5\n\ngenerate_samp_max &lt;- function(mu, sigma, n) {\n  \n  single_sample &lt;- rexp(n, lambda)\n  sample_max &lt;- max(single_sample)\n  \n  return(sample_max)\n}\n\n## test function once:\ngenerate_samp_max(mu = mu, sigma = sigma, n = n)\n\n[1] 0.9294892\n\nnsim &lt;- 5000      # number of simulations\n\n## code to map through the function. \n## the \\(i) syntax says to just repeat the generate_samp_mean function\n## nsim times\nmaxs &lt;- map_dbl(1:nsim, \\(i) generate_samp_max(mu = mu, sigma = sigma, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmaxs_df &lt;- tibble(maxs)\nmaxs_df\n\n# A tibble: 5,000 × 1\n    maxs\n   &lt;dbl&gt;\n 1  3.03\n 2  3.80\n 3  4.08\n 4  2.62\n 5  5.06\n 6  4.87\n 7  7.68\n 8  5.27\n 9  2.78\n10 11.3 \n# ℹ 4,990 more rows\n\nggplot(data = maxs_df, aes(x = maxs)) +\n  geom_histogram(colour = \"deeppink4\", fill = \"deeppink1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Means\",\n       title = paste(\"Sampling Distribution of the \\nSample Mean when n =\", n))\n\n\n\n\n\n\n\nmaxs_df |&gt;\n  summarise(mean_samp_dist = mean(maxs),\n            var_samp_dist = var(maxs),\n            sd_samp_dist = sd(maxs))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1           4.56          5.74         2.40\n##beta\nn &lt;- 5            # sample size\nmu &lt;- 0.8         # population mean\nsigma &lt;- 0.1206    # population standard deviation (calculated by hand)\na=8\nb=2\n\ngenerate_samp_min &lt;- function(mu, sigma, n) {\n  \n  single_sample &lt;- rbeta(n,a,b)\n  sample_min &lt;- min(single_sample)\n  \n  return(sample_min)\n}\n\n## test function once:\ngenerate_samp_min(mu = mu, sigma = sigma, n = n)\n\n[1] 0.698269\n\nnsim &lt;- 5000      # number of simulations\n\n## code to map through the function. \n## the \\(i) syntax says to just repeat the generate_samp_mean function\n## nsim times\nmins &lt;- map_dbl(1:nsim, \\(i) generate_samp_min(mu = mu, sigma = sigma, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmins_df &lt;- tibble(mins)\nmins_df\n\n# A tibble: 5,000 × 1\n    mins\n   &lt;dbl&gt;\n 1 0.773\n 2 0.487\n 3 0.640\n 4 0.696\n 5 0.709\n 6 0.837\n 7 0.628\n 8 0.812\n 9 0.708\n10 0.794\n# ℹ 4,990 more rows\n\nggplot(data = mins_df, aes(x = mins)) +\n  geom_histogram(colour = \"deeppink4\", fill = \"deeppink1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Mins\",\n       title = paste(\"Sampling Distribution of the \\nSample Mean when n =\", n))\n\n\n\n\n\n\n\nmins_df |&gt;\n  summarise(mean_samp_dist = mean(mins),\n            var_samp_dist = var(mins),\n            sd_samp_dist = sd(mins))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1          0.646        0.0110        0.105\nn &lt;- 5            # sample size\nmu &lt;- 0.8         # population mean\nsigma &lt;- 0.1206    # population standard deviation (calculated by hand)\na=8\nb=2\n\ngenerate_samp_max &lt;- function(mu, sigma, n) {\n  \n  single_sample &lt;- rbeta(n,a,b)\n  sample_max &lt;- max(single_sample)\n  \n  return(sample_max)\n}\n\n## test function once:\ngenerate_samp_max(mu = mu, sigma = sigma, n = n)\n\n[1] 0.9628284\n\nnsim &lt;- 5000      # number of simulations\n\n## code to map through the function. \n## the \\(i) syntax says to just repeat the generate_samp_mean function\n## nsim times\nmaxs &lt;- map_dbl(1:nsim, \\(i) generate_samp_max(mu = mu, sigma = sigma, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmaxs_df &lt;- tibble(maxs)\nmaxs_df\n\n# A tibble: 5,000 × 1\n    maxs\n   &lt;dbl&gt;\n 1 0.993\n 2 0.899\n 3 0.851\n 4 0.883\n 5 0.903\n 6 0.927\n 7 0.978\n 8 0.944\n 9 0.983\n10 0.949\n# ℹ 4,990 more rows\n\nggplot(data = maxs_df, aes(x = maxs)) +\n  geom_histogram(colour = \"deeppink4\", fill = \"deeppink1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Means\",\n       title = paste(\"Sampling Distribution of the \\nSample Mean when n =\", n))\n\n\n\n\n\n\n\nmaxs_df |&gt;\n  summarise(mean_samp_dist = mean(maxs),\n            var_samp_dist = var(maxs),\n            sd_samp_dist = sd(maxs))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1          0.921       0.00213       0.0461\n##min\nn &lt;- 5\n## CHANGE 0 and 3 to represent where you want your graph to start and end\n## on the x-axis\nx &lt;- seq(0, 10, length.out = 1000)\n## CHANGE to be the pdf you calculated. Note that, as of now, \n## this is not a proper density (it does not integrate to 1).\ndensity &lt;- 5 * (1 - (1 - exp(-0.5 * x))^4) * (0.5 * exp(-0.5 * x))\n\n\n\n## put into tibble and plot\nsamp_min_df &lt;- tibble(x, density)\nggplot(data = samp_min_df, aes(x = x, y = density)) +\n  geom_line() +\n  theme_minimal()\nn &lt;- 5\n## CHANGE 0 and 3 to represent where you want your graph to start and end\n## on the x-axis\nx &lt;- seq(0, 10, length.out = 1000)\n## CHANGE to be the pdf you calculated. Note that, as of now, \n## this is not a proper density (it does not integrate to 1).\ndensity &lt;- 5 * (1 - exp(-0.5 * x)^4)*(0.5 * exp(-0.5 * x))\n\n\n\n## put into tibble and plot\nsamp_min_df &lt;- tibble(x, density)\nggplot(data = samp_min_df, aes(x = x, y = density)) +\n  geom_line() +\n  theme_minimal()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Final_Portfolio_Dean",
    "section": "",
    "text": "test test test\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMini-Project-1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nindex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMini Project 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMini-Project-3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMini-Project-4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMini-Reflect\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMini-Project 5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nApr 28, 2025\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nApr 25, 2025\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/01-simulation/index.html",
    "href": "posts/01-simulation/index.html",
    "title": "index",
    "section": "",
    "text": "##Jy lyk mooi"
  },
  {
    "objectID": "posts/03-Mini/index.html",
    "href": "posts/03-Mini/index.html",
    "title": "Mini-Project-3",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tibble)\n\n\np=0.1\n\ngenerate_samp_prop &lt;- function(n,p) {\n  \n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  lb &lt;-phat -2.132*sqrt(phat* (1-phat)/n)\n  ub &lt;-phat +2.132*sqrt(phat* (1-phat)/n)\n  \n  prop_df &lt;-tibble(phat,lb,ub)\n  return(prop_df)\n}\ngenerate_samp_prop(n=5, p=0.1)\n\n# A tibble: 1 × 3\n   phat     lb    ub\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1   0.2 -0.181 0.581\n\nn_sim &lt;-5000\n\nprop_ci_df &lt;-map(1:n_sim, \\ (i) generate_samp_prop(n=5, p =0.1)) |&gt; bind_rows()\n\nprop_ci_df &lt;- prop_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\n\nprop_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.329         0.402\n\n\n\np=0.1\ngenerate_samp_prop &lt;- function(n,p) {\n  \n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  lb &lt;-phat -2.132*sqrt(phat* (1-phat)/n)\n  ub &lt;-phat +2.132*sqrt(phat* (1-phat)/n)\n  \n  prop_df &lt;-tibble(phat,lb,ub)\n  return(prop_df)\n}\ngenerate_samp_prop(n=5, p=0.1)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0     0     0\n\nn_sim &lt;-5000\n\nprop_ci_df &lt;-map(1:n_sim, \\ (i) generate_samp_prop(n=5, p =0.1)) |&gt; bind_rows()\n\nprop_ci_df &lt;- prop_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\n\nprop_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.333         0.409\n\n\n\np=0.55\ngenerate_samp_prop &lt;- function(n,p) {\n  \n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  lb &lt;-phat -2.132*sqrt(phat* (1-phat)/n)\n  ub &lt;-phat +2.132*sqrt(phat* (1-phat)/n)\n  \n  prop_df &lt;-tibble(phat,lb,ub)\n  return(prop_df)\n}\ngenerate_samp_prop(n=5, p=0.55)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   0.8 0.419  1.18\n\nn_sim &lt;-5000\n\nprop_ci_df &lt;-map(1:n_sim, \\ (i) generate_samp_prop(n=5, p =0.55)) |&gt; bind_rows()\n\nprop_ci_df &lt;- prop_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\n\nprop_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.817         0.934\n\n\n\np=0.1\ngenerate_samp_prop &lt;- function(n,p) {\n  \n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  lb &lt;-phat -1.684*sqrt(phat* (1-phat)/n)\n  ub &lt;-phat +1.6842*sqrt(phat* (1-phat)/n)\n  \n  prop_df &lt;-tibble(phat,lb,ub)\n  return(prop_df)\n}\ngenerate_samp_prop(n=40, p=0.1)\n\n# A tibble: 1 × 3\n   phat       lb    ub\n  &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1  0.05 -0.00803 0.108\n\nn_sim &lt;-5000\n\nprop_ci_df &lt;-map(1:n_sim, \\ (i) generate_samp_prop(n=40, p =0.1)) |&gt; bind_rows()\n\nprop_ci_df &lt;- prop_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\n\nprop_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.152         0.902\n\n\n\np=0.55\ngenerate_samp_prop &lt;- function(n,p) {\n  \n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  lb &lt;-phat -1.684*sqrt(phat* (1-phat)/n)\n  ub &lt;-phat +1.6842*sqrt(phat* (1-phat)/n)\n  \n  prop_df &lt;-tibble(phat,lb,ub)\n  return(prop_df)\n}\ngenerate_samp_prop(n=40, p=0.55)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.575 0.443 0.707\n\nn_sim &lt;-5000\n\nprop_ci_df &lt;-map(1:n_sim, \\ (i) generate_samp_prop(n=40, p =0.55)) |&gt; bind_rows()\n\nprop_ci_df &lt;- prop_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\n\nprop_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.261         0.886\n\n\n\np=0.1\ngenerate_samp_prop &lt;- function(n,p) {\n  \n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  lb &lt;-phat -1.645*sqrt(phat* (1-phat)/n)\n  ub &lt;-phat +1.645*sqrt(phat* (1-phat)/n)\n  \n  prop_df &lt;-tibble(phat,lb,ub)\n  return(prop_df)\n}\ngenerate_samp_prop(n=300, p=0.1)\n\n# A tibble: 1 × 3\n    phat     lb    ub\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 0.0967 0.0686 0.125\n\nn_sim &lt;-5000\n\nprop_ci_df &lt;-map(1:n_sim, \\ (i) generate_samp_prop(n=300, p =0.1)) |&gt; bind_rows()\n\nprop_ci_df &lt;- prop_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\n\nprop_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1    0.0567         0.888\n\n\n\np=0.55\ngenerate_samp_prop &lt;- function(n,p) {\n  \n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  lb &lt;-phat -1.645*sqrt(phat* (1-phat)/n)\n  ub &lt;-phat +1.645*sqrt(phat* (1-phat)/n)\n  \n  prop_df &lt;-tibble(phat,lb,ub)\n  return(prop_df)\n}\ngenerate_samp_prop(n=300, p=0.55)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  0.57 0.523 0.617\n\nn_sim &lt;-5000\n\nprop_ci_df &lt;-map(1:n_sim, \\ (i) generate_samp_prop(n=300, p =0.55)) |&gt; bind_rows()\n\nprop_ci_df &lt;- prop_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\n\nprop_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1    0.0943         0.892\n\n\n|  |         | $n = $5 | $n = $40 | $n = $300 |\n|:----:|:-----------------:|:-------------:|:------------:|:------------:|\n| $p = 0.1$   | Coverage Rate       | 0.4   |  0.9072     |  0.8838         |\n| $p = 0.55$   | Coverage Rate       |0.93     |0.8846   | 0.897    |\n|    |                     |               |              |              |\n| $p = 0.1$    | Average Width        |0.332   |  0.152  |   0.057       |\n| $p = 0.55$    | Average Width        |0.817  |  0.262     |  0.094      |\n\n\n: Table of Results {.striped .hover}"
  },
  {
    "objectID": "posts/06-reflect/index.html",
    "href": "posts/06-reflect/index.html",
    "title": "Mini-Reflect",
    "section": "",
    "text": "Question 1\nThe first mini project is looking at the standard error and expected value of different distributions like the uniform, normal and beta distribution for example.\nMini-project two related to the coursework by using the modern approach to teaching math stat. By writing a story with defintions and terms, you are having to not just do the math but understand it which is what the course is trying to achieve. In my mini-project 2, I explained missiles strike rate using a binonmial distribution, and this is related to the coursework goal of being able to explain ideas from the class, not just do the math.\nAfter we have looked at where the p value comes from and using p values a lot, mini-project 5 serves as warning to, us future possible statisticians\nlibrary(usethis)\ninstall.packages(““)\nusethis::usegit\nusethis::use_github()\nI personally really enjoyed the mini-projects as it gave me some time to do repeated processes and see what is happening. When we would have to change small things of code, many times in different places, it really helped me understand the code and then the concepts as I am someone who needs to repeat tasks to fully understand it."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  }
]