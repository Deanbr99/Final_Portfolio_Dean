---
title: "Mini-Project 5"
---

Dean Brooker Mini-Project 5

1.  ***Towards the end of Section 1*****, the authors say “As ‘statistical significance’ is used less, statistical thinking will be used more.” Elaborate on what you think the authors mean. Give some examples of what you think embodies “statistical thinking.”**

What I think the author means is the idea that as people move away from saying whether a finding is relevant will no longer be simply judged by it simply passing a p value test, but the research will be judged by whether the researcher can argue their methods and findings in a way that proves a point. An example of statistical thinking in my eyes is if the researcher gets a p value of 0.1, they will be able to argue why it is 0.1 and not below 0.05, and why this research is still relevant even if the p value is 0.1.An example could be, a new improvement to squash balls increased rallies by 15 seconds per rally on average but the p value is 0.07, then the statistical thinking should look more into this, maybe get more data, rerun the study. Just because it failed, doesn’t mean there isn’t something there.

2.  ***Section 2, third paragraph*****: The authors state “A label of statistical significance adds nothing to what is already conveyed by the value of p; in fact, this dichotomization of p-values makes matters worse.” Elaborate on what you think the authors means.**

What I think the author is trying to get at is that a p value being said to be significant and proving something does not mean that it is true. A very low p value just means the result is very rare if there were no real effects so researchers should use thinking to convince the reader that the research shows something important rather than hiding behind a p value just to prove what they studying has an effect. The author is saying that when people say 0.049 is significant and 0.051 is not significant, the problem is just being made worse because researchers have something to hide behind when judged. Someone could say, “I don’t think your research on whether carrots help you see in the dark proves anything, a researchers can simply say, “Its significant” and the current scientist community will back up the researcher and not be curious like the person challenging the researcher.

3.  ***Section 2, end of first column*****: The authors state “For the integrity of scientific publishing and research dissemination, therefore, whether a p-value passes any arbitrary threshold should not be considered at all when deciding which results to present or highlight.” Do you agree or disagree? How should it be decided which results to present/highlight in scientific publishing?**

I do not think p values should be, the be all and end all. Last semester for my econometrics project, we investigated whether EV cars has reduced carbon emissions in the US. The obvious and truthful answer is absolutely no. There are so few EV cars in the US, it is just really not having an effect yet on reducing carbon emissions in the US by state. But in our research we changed the variable of research to EV/per-capita in each state and with that, that variable was significant at a 0.05 level. Therefore, we could write a paper that portrayed on a per capita basis, EV cars are already influencing reducing carbon emissions. What I am trying to say is, if I, a very terrible academic could “create” significance, a great academic with more time could easily create significance out of nothing. The p value should not be the reason academic research should be highlighted

The way I think research should be presented, is if the researcher themselves pave the way for future of research in the field and not by proving something. For example, I think a researcher who says, “I have proved cursive writing improves attention to detail in children” should not be highlighted but the researcher that says, “Cursive writing improves attention to detail in kids, through my extensive research, more research and areas of interest in this topic is whether this increased attention to detail decreases creativity in children. I think research should highlighted and published if its sole purpose is to pave the future and not give “significance” and recognition to a researcher.

***4)Section 3, end of page 2*****: The authors state “The statistical community has not yet converged on a simple paradigm for the use of statistical inference in scientific research – and in fact it may never do so. A one-size-fits-all approach to statistical inference is an inappropriate expectation.” Do you agree or disagree? Explain.**

Yes I agree with this. I agree that we should move away from the one size fits all. Different research should use different methods to decide on significance. With data from hospitals as discussed, often with large amounts of data it is easy to get a small p value but maybe with another method that is discussed, like false positive risk or analysis or credibility, a fuller picture can be portrayed. I do not know anything about those methods and that is sad in my eyes. Reading about all these other methods only in my senior year of college is sad and says something about academia. Academia is so pushed in the one size fits all, us college students aren’t getting the opportunity to be exposed to anything but the p value. If we start teaching undergraduates about other methods, maybe the next generation can be more thoughtful in statistical inference.

***5) Section 3.2*****: The authors note that they are envisioning “a sort of ‘statistical thoughtfulness’.” What do you think “statistical thoughtfulness” means? What are some ways to demonstrate “statistical thoughtfulness” in an analysis?**

I really liked the idea that, thoughtful research means being cautious with language and avoiding overconfident terms like “significant”. Often a paper says, for certain this is what is happening and then 3 years later another paper shows the previous paper was wrong. The first paper could have signs that they know they were wrong but they used overconfident language and try make their research sound more significant just to get published or highlighted. This paper argues that statistical thoughtfulness is presenting info not just so they can get published. An example would be clearly explaining what the confidence interval tells you and what it doesn’t tell us. It is presenting a picture and also explaining what picture it is not telling.

***6) Section 3.2.4*****: A few of the authors of papers in this special issue argue that some of the terminology used in statistics, such as “significance” and “confidence” can be misleading, and they propose the use of “compatibility” instead. What you do you think they believe the problem is? Do you agree or disagree (that there is a problem and that changing the name will help)?**

They think the problem currently is “confidence” and significance is too strong of language. Significant means important and confidence sounds too certain.

I do not agree with this really. I think just changing the wording is not at the root problem. Yes, I understand, all these suggestions paired with each other, moves the statistics community forward but I think changing language is low on the list. I think, this suggestion is too old school of thought, like that it is language that is the problem, but I think it is the method, data and inference, which is more of the problem

**7) Find a quote or point that really strikes you (i.e., made you think). What is the quote (and tell me where to find it), and why does it stand out to you?**

*“Edgeworth’s (1885) original intention for statistical significance was simply as a tool to indicate when a result warrants further scrutiny.”*

From a bit of reading online, it appears that Edgeworth introduced many early ideas about the use of probability and inference in statistics. He argues that statistical significance should be a signal for further scrutiny and investigation and not a final decision. I was very interested in Edgeworth so I looked him up a bit. It was difficult to find stuff. Playing around with ChatGPT, it said that, Edgeworth believed that different problems may require different statistical tools and probability should be viewed as a tool for reasoned judgement. I could not find the sources, AI was referring to but if this info is true, it is incredible to see that someone so long ago, was saying exactly what this author was saying.
